environment:
  A: [1., 1.]
  C: [1., 1.]
  mu_0 : 0.25
  sigma: 0.
  a_0: -1.
  N: 2
price_bounds: [1.0, 2.8]
optimization_cases: 
  - name: best_response_penalised
    agent:
      type: ExtortionAgent
      params:
        map_type: custom
        map_params_path: "custom_parameters/best_response_params.txt"
    delay: 0.0
    n_competitions: 1
    T: 20
    skip_steps: 15
    penalty_coeff: 100
    learning_agent_initial_price: 1.5
    extortion_agent_initial_price: 1.5
  - name: self_play
    agent:
      type: ExtortionAgentSelfPlay
      params:
        dummy: true
    delay: 0.5
    n_competitions: 1
    T: 20
    skip_steps: 15
    learning_agent_initial_price: 1.5
    extortion_agent_initial_price: 1.5
  - name: sw_uts
    agent:
      type: SW_UTS
      params:
        n_actions: 51
        n_neighbors: 2
        sliding_window: 50
        std: 0.01
    delay: 1.
    n_competitions: 20
    T: 500
    skip_steps: 0
    learning_agent_initial_price: 1.5
    extortion_agent_initial_price: 1.5
    penalty_coeff: 1000
extortion_agent:
  type: ExtortionAgent
  params:
    map_type: monotone_equispaced
    n_params: 14
optimization:
  maxfevals: 1000
  seed: 42
  sigma0: 0.8
  param_bounds: [0., 6.]
  weights: [1., 10., 0.05]


